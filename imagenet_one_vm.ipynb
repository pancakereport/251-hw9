{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82885bb9",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.cuda.amp import GradScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efaef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"/data/runs\")\n",
    "#!tensorboard --logdir=/data/runs #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4326e42",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "GPU = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe1cf28",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5493005c",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b67153",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe7fcc6",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ffb1171",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 2\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 100\n",
    "TRAIN_BATCH=128\n",
    "VAL_BATCH=128\n",
    "WORKERS=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6198327",
   "metadata": {
    "id": "85299ee3"
   },
   "outputs": [],
   "source": [
    "TRAINDIR=\"/data/train2\"\n",
    "VALDIR=\"/data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440b97c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1622949197302,
     "user": {
      "displayName": "Jayanth Srinivasa",
      "photoUrl": "",
      "userId": "03369694624178485882"
     },
     "user_tz": 420
    },
    "id": "c6bf6a83",
    "outputId": "72d2e92f-7574-4c0a-c813-288cd69eaa36"
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "149f94a3",
   "metadata": {
    "id": "acd97390"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.set_device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7778402e",
   "metadata": {
    "id": "e19a5849"
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257a352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9473a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step_train = 0\n",
    "global_step_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69807f8f",
   "metadata": {
    "id": "4e65743f"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step_train\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        #optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", losses.avg, global_step = global_step_train)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step_train)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step_train)\n",
    "        global_step_train += 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ece085",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step_val\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                output = model(images)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step_val)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step_val)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step_val)\n",
    "    global_step_val += 1\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b045d3b",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2d11be4",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45cf008d",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e91f268f",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "777e950e",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71321c20",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "717e5bdb",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb1e02b9",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "#IMG_SIZE = 32 cinic size\n",
    "IMG_SIZE = 224 # i think this is right for imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60b1974f",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "# imagenet has 1000 classes\n",
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41804ab7",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7b0f0e6",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf = model.fc.in_features\n",
    "inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ffed0f8",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1782c739",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d96e8935",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d0b818f",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cfd8232",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fd02324",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    #transforms.RandomCrop(I),\n",
    "    #transforms.Rescale(32),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8731d2dc",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09a1b89e",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    #transforms.Rescale(32),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "444479c2",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88d3d7f5",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ccaf29d",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b8043e9",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85ba1f48",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][    0/10010]\tTime  3.043 ( 3.043)\tData  1.270 ( 1.270)\tLoss 7.0402e+00 (7.0402e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Epoch: [0][  100/10010]\tTime  0.077 ( 0.276)\tData  0.001 ( 0.182)\tLoss 6.8359e+00 (7.0223e+00)\tAcc@1   0.78 (  0.19)\tAcc@5   2.34 (  0.89)\n",
      "Epoch: [0][  200/10010]\tTime  0.077 ( 0.271)\tData  0.001 ( 0.186)\tLoss 6.8120e+00 (6.9221e+00)\tAcc@1   0.00 (  0.30)\tAcc@5   0.78 (  1.23)\n",
      "Epoch: [0][  300/10010]\tTime  0.077 ( 0.268)\tData  0.001 ( 0.186)\tLoss 6.6579e+00 (6.8589e+00)\tAcc@1   0.00 (  0.36)\tAcc@5   1.56 (  1.45)\n",
      "Epoch: [0][  400/10010]\tTime  0.077 ( 0.265)\tData  0.001 ( 0.185)\tLoss 6.6954e+00 (6.8076e+00)\tAcc@1   0.00 (  0.41)\tAcc@5   3.12 (  1.63)\n",
      "Epoch: [0][  500/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.184)\tLoss 6.6104e+00 (6.7617e+00)\tAcc@1   1.56 (  0.46)\tAcc@5   5.47 (  1.90)\n",
      "Epoch: [0][  600/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.184)\tLoss 6.4093e+00 (6.7164e+00)\tAcc@1   0.78 (  0.51)\tAcc@5   3.91 (  2.19)\n",
      "Epoch: [0][  700/10010]\tTime  0.080 ( 0.263)\tData  0.001 ( 0.184)\tLoss 6.1991e+00 (6.6691e+00)\tAcc@1   2.34 (  0.60)\tAcc@5   7.03 (  2.48)\n",
      "Epoch: [0][  800/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.185)\tLoss 6.2262e+00 (6.6212e+00)\tAcc@1   1.56 (  0.68)\tAcc@5   6.25 (  2.77)\n",
      "Epoch: [0][  900/10010]\tTime  0.080 ( 0.264)\tData  0.001 ( 0.186)\tLoss 6.3140e+00 (6.5740e+00)\tAcc@1   1.56 (  0.78)\tAcc@5   3.91 (  3.13)\n",
      "Epoch: [0][ 1000/10010]\tTime  0.082 ( 0.264)\tData  0.001 ( 0.186)\tLoss 5.9783e+00 (6.5262e+00)\tAcc@1   3.12 (  0.88)\tAcc@5   7.03 (  3.47)\n",
      "Epoch: [0][ 1100/10010]\tTime  0.099 ( 0.265)\tData  0.009 ( 0.187)\tLoss 5.9800e+00 (6.4853e+00)\tAcc@1   2.34 (  0.98)\tAcc@5  10.16 (  3.82)\n",
      "Epoch: [0][ 1200/10010]\tTime  0.077 ( 0.265)\tData  0.001 ( 0.187)\tLoss 6.0963e+00 (6.4437e+00)\tAcc@1   1.56 (  1.09)\tAcc@5   8.59 (  4.17)\n",
      "Epoch: [0][ 1300/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.187)\tLoss 5.9648e+00 (6.4047e+00)\tAcc@1   2.34 (  1.19)\tAcc@5   8.59 (  4.51)\n",
      "Epoch: [0][ 1400/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.187)\tLoss 5.8663e+00 (6.3667e+00)\tAcc@1   3.91 (  1.31)\tAcc@5  10.16 (  4.89)\n",
      "Epoch: [0][ 1500/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.186)\tLoss 5.5424e+00 (6.3298e+00)\tAcc@1   4.69 (  1.42)\tAcc@5  15.62 (  5.27)\n",
      "Epoch: [0][ 1600/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.186)\tLoss 5.7632e+00 (6.2959e+00)\tAcc@1   4.69 (  1.53)\tAcc@5  10.16 (  5.60)\n",
      "Epoch: [0][ 1700/10010]\tTime  0.303 ( 0.263)\tData  0.227 ( 0.186)\tLoss 5.8460e+00 (6.2606e+00)\tAcc@1   3.12 (  1.64)\tAcc@5  10.16 (  5.95)\n",
      "Epoch: [0][ 1800/10010]\tTime  0.139 ( 0.263)\tData  0.062 ( 0.186)\tLoss 5.5794e+00 (6.2273e+00)\tAcc@1   3.12 (  1.76)\tAcc@5  13.28 (  6.32)\n",
      "Epoch: [0][ 1900/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.6826e+00 (6.1957e+00)\tAcc@1   3.91 (  1.90)\tAcc@5  11.72 (  6.69)\n",
      "Epoch: [0][ 2000/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.7209e+00 (6.1641e+00)\tAcc@1   4.69 (  2.03)\tAcc@5   7.81 (  7.07)\n",
      "Epoch: [0][ 2100/10010]\tTime  0.076 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.5777e+00 (6.1346e+00)\tAcc@1   4.69 (  2.14)\tAcc@5  12.50 (  7.42)\n",
      "Epoch: [0][ 2200/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.3042e+00 (6.1063e+00)\tAcc@1   6.25 (  2.26)\tAcc@5  15.62 (  7.76)\n",
      "Epoch: [0][ 2300/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.2488e+00 (6.0766e+00)\tAcc@1   5.47 (  2.39)\tAcc@5  14.84 (  8.12)\n",
      "Epoch: [0][ 2400/10010]\tTime  0.087 ( 0.263)\tData  0.010 ( 0.186)\tLoss 5.4805e+00 (6.0494e+00)\tAcc@1   6.25 (  2.52)\tAcc@5  14.06 (  8.45)\n",
      "Epoch: [0][ 2500/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.4151e+00 (6.0233e+00)\tAcc@1   4.69 (  2.64)\tAcc@5  17.19 (  8.78)\n",
      "Epoch: [0][ 2600/10010]\tTime  0.078 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.2938e+00 (5.9970e+00)\tAcc@1   4.69 (  2.76)\tAcc@5  14.84 (  9.12)\n",
      "Epoch: [0][ 2700/10010]\tTime  0.086 ( 0.263)\tData  0.010 ( 0.186)\tLoss 5.1773e+00 (5.9708e+00)\tAcc@1   6.25 (  2.90)\tAcc@5  17.19 (  9.47)\n",
      "Epoch: [0][ 2800/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.0165e+00 (5.9465e+00)\tAcc@1  13.28 (  3.02)\tAcc@5  23.44 (  9.80)\n",
      "Epoch: [0][ 2900/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.1527e+00 (5.9216e+00)\tAcc@1   7.81 (  3.16)\tAcc@5  21.88 ( 10.16)\n",
      "Epoch: [0][ 3000/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.0903e+00 (5.8973e+00)\tAcc@1   9.38 (  3.30)\tAcc@5  26.56 ( 10.50)\n",
      "Epoch: [0][ 3100/10010]\tTime  0.078 ( 0.263)\tData  0.002 ( 0.186)\tLoss 5.1847e+00 (5.8743e+00)\tAcc@1   7.03 (  3.43)\tAcc@5  17.97 ( 10.82)\n",
      "Epoch: [0][ 3200/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 4.9690e+00 (5.8516e+00)\tAcc@1  11.72 (  3.57)\tAcc@5  23.44 ( 11.14)\n",
      "Epoch: [0][ 3300/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.0284e+00 (5.8284e+00)\tAcc@1   7.81 (  3.70)\tAcc@5  27.34 ( 11.47)\n",
      "Epoch: [0][ 3400/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 5.1121e+00 (5.8068e+00)\tAcc@1   6.25 (  3.84)\tAcc@5  17.19 ( 11.79)\n",
      "Epoch: [0][ 3500/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.186)\tLoss 5.3388e+00 (5.7846e+00)\tAcc@1   6.25 (  3.99)\tAcc@5  15.62 ( 12.12)\n",
      "Epoch: [0][ 3600/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 4.7105e+00 (5.7631e+00)\tAcc@1  12.50 (  4.13)\tAcc@5  30.47 ( 12.44)\n",
      "Epoch: [0][ 3700/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 5.0370e+00 (5.7415e+00)\tAcc@1   7.81 (  4.27)\tAcc@5  19.53 ( 12.76)\n",
      "Epoch: [0][ 3800/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 5.2272e+00 (5.7211e+00)\tAcc@1   6.25 (  4.40)\tAcc@5  17.19 ( 13.08)\n",
      "Epoch: [0][ 3900/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 4.9552e+00 (5.7008e+00)\tAcc@1  10.16 (  4.53)\tAcc@5  25.78 ( 13.39)\n",
      "Epoch: [0][ 4000/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.186)\tLoss 4.9256e+00 (5.6807e+00)\tAcc@1  12.50 (  4.67)\tAcc@5  30.47 ( 13.70)\n",
      "Epoch: [0][ 4100/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.186)\tLoss 4.8590e+00 (5.6612e+00)\tAcc@1  10.16 (  4.81)\tAcc@5  25.00 ( 14.01)\n",
      "Epoch: [0][ 4200/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.186)\tLoss 4.9753e+00 (5.6415e+00)\tAcc@1  10.16 (  4.95)\tAcc@5  28.12 ( 14.32)\n",
      "Epoch: [0][ 4300/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.186)\tLoss 5.1366e+00 (5.6219e+00)\tAcc@1   8.59 (  5.10)\tAcc@5  19.53 ( 14.64)\n",
      "Epoch: [0][ 4400/10010]\tTime  0.087 ( 0.262)\tData  0.011 ( 0.186)\tLoss 4.7835e+00 (5.6030e+00)\tAcc@1   8.59 (  5.24)\tAcc@5  29.69 ( 14.94)\n",
      "Epoch: [0][ 4500/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.186)\tLoss 4.9266e+00 (5.5843e+00)\tAcc@1  10.16 (  5.38)\tAcc@5  29.69 ( 15.23)\n",
      "Epoch: [0][ 4600/10010]\tTime  0.079 ( 0.262)\tData  0.003 ( 0.185)\tLoss 4.6941e+00 (5.5661e+00)\tAcc@1  15.62 (  5.52)\tAcc@5  28.91 ( 15.53)\n",
      "Epoch: [0][ 4700/10010]\tTime  0.080 ( 0.262)\tData  0.004 ( 0.185)\tLoss 4.6405e+00 (5.5477e+00)\tAcc@1   9.38 (  5.66)\tAcc@5  23.44 ( 15.82)\n",
      "Epoch: [0][ 4800/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 4.5391e+00 (5.5294e+00)\tAcc@1  15.62 (  5.80)\tAcc@5  30.47 ( 16.11)\n",
      "Epoch: [0][ 4900/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 4.3504e+00 (5.5114e+00)\tAcc@1  13.28 (  5.93)\tAcc@5  34.38 ( 16.41)\n",
      "Epoch: [0][ 5000/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 4.4156e+00 (5.4943e+00)\tAcc@1  14.84 (  6.06)\tAcc@5  33.59 ( 16.68)\n",
      "Epoch: [0][ 5100/10010]\tTime  0.077 ( 0.262)\tData  0.002 ( 0.185)\tLoss 4.7110e+00 (5.4770e+00)\tAcc@1  11.72 (  6.20)\tAcc@5  30.47 ( 16.96)\n",
      "Epoch: [0][ 5200/10010]\tTime  0.077 ( 0.261)\tData  0.001 ( 0.185)\tLoss 4.6429e+00 (5.4599e+00)\tAcc@1   7.03 (  6.33)\tAcc@5  26.56 ( 17.24)\n",
      "Epoch: [0][ 5300/10010]\tTime  0.077 ( 0.261)\tData  0.002 ( 0.185)\tLoss 4.8561e+00 (5.4435e+00)\tAcc@1  11.72 (  6.46)\tAcc@5  29.69 ( 17.51)\n",
      "Epoch: [0][ 5400/10010]\tTime  0.114 ( 0.261)\tData  0.037 ( 0.185)\tLoss 4.8458e+00 (5.4270e+00)\tAcc@1   8.59 (  6.59)\tAcc@5  20.31 ( 17.78)\n",
      "Epoch: [0][ 5500/10010]\tTime  0.077 ( 0.261)\tData  0.001 ( 0.185)\tLoss 4.5474e+00 (5.4106e+00)\tAcc@1  14.84 (  6.73)\tAcc@5  28.91 ( 18.06)\n",
      "Epoch: [0][ 5600/10010]\tTime  0.077 ( 0.261)\tData  0.001 ( 0.185)\tLoss 4.2906e+00 (5.3940e+00)\tAcc@1  17.97 (  6.88)\tAcc@5  36.72 ( 18.33)\n",
      "Epoch: [0][ 5700/10010]\tTime  0.077 ( 0.261)\tData  0.001 ( 0.185)\tLoss 4.5680e+00 (5.3781e+00)\tAcc@1  14.84 (  7.02)\tAcc@5  30.47 ( 18.61)\n",
      "Epoch: [0][ 5800/10010]\tTime  0.077 ( 0.261)\tData  0.001 ( 0.185)\tLoss 4.4083e+00 (5.3625e+00)\tAcc@1  16.41 (  7.15)\tAcc@5  34.38 ( 18.87)\n",
      "Epoch: [0][ 5900/10010]\tTime  0.077 ( 0.261)\tData  0.001 ( 0.185)\tLoss 4.5009e+00 (5.3470e+00)\tAcc@1  14.84 (  7.29)\tAcc@5  36.72 ( 19.14)\n",
      "Epoch: [0][ 6000/10010]\tTime  0.077 ( 0.261)\tData  0.001 ( 0.185)\tLoss 4.4958e+00 (5.3311e+00)\tAcc@1  16.41 (  7.42)\tAcc@5  35.16 ( 19.40)\n",
      "Epoch: [0][ 6100/10010]\tTime  0.084 ( 0.261)\tData  0.001 ( 0.185)\tLoss 4.5437e+00 (5.3153e+00)\tAcc@1  14.06 (  7.57)\tAcc@5  28.12 ( 19.67)\n",
      "Epoch: [0][ 6200/10010]\tTime  0.078 ( 0.262)\tData  0.001 ( 0.185)\tLoss 4.2228e+00 (5.3004e+00)\tAcc@1  10.16 (  7.70)\tAcc@5  35.94 ( 19.92)\n",
      "Epoch: [0][ 6300/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 4.5614e+00 (5.2861e+00)\tAcc@1  14.06 (  7.82)\tAcc@5  30.47 ( 20.17)\n",
      "Epoch: [0][ 6400/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 4.1230e+00 (5.2719e+00)\tAcc@1  17.97 (  7.95)\tAcc@5  42.19 ( 20.42)\n",
      "Epoch: [0][ 6500/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.185)\tLoss 4.4199e+00 (5.2575e+00)\tAcc@1  17.19 (  8.07)\tAcc@5  35.16 ( 20.67)\n",
      "Epoch: [0][ 6600/10010]\tTime  0.077 ( 0.262)\tData  0.001 ( 0.186)\tLoss 4.1385e+00 (5.2431e+00)\tAcc@1  18.75 (  8.21)\tAcc@5  44.53 ( 20.92)\n",
      "Epoch: [0][ 6700/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 4.5953e+00 (5.2294e+00)\tAcc@1  10.16 (  8.33)\tAcc@5  29.69 ( 21.15)\n",
      "Epoch: [0][ 6800/10010]\tTime  0.403 ( 0.263)\tData  0.323 ( 0.186)\tLoss 4.0715e+00 (5.2148e+00)\tAcc@1  15.62 (  8.47)\tAcc@5  40.62 ( 21.40)\n",
      "Epoch: [0][ 6900/10010]\tTime  0.110 ( 0.263)\tData  0.034 ( 0.186)\tLoss 4.1816e+00 (5.2007e+00)\tAcc@1  18.75 (  8.60)\tAcc@5  36.72 ( 21.65)\n",
      "Epoch: [0][ 7000/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 3.9067e+00 (5.1869e+00)\tAcc@1  26.56 (  8.73)\tAcc@5  46.09 ( 21.89)\n",
      "Epoch: [0][ 7100/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.186)\tLoss 4.1845e+00 (5.1731e+00)\tAcc@1  18.75 (  8.87)\tAcc@5  42.97 ( 22.13)\n",
      "Epoch: [0][ 7200/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.187)\tLoss 4.0938e+00 (5.1600e+00)\tAcc@1  21.09 (  9.00)\tAcc@5  42.97 ( 22.36)\n",
      "Epoch: [0][ 7300/10010]\tTime  0.077 ( 0.263)\tData  0.001 ( 0.187)\tLoss 4.2336e+00 (5.1466e+00)\tAcc@1  15.62 (  9.13)\tAcc@5  37.50 ( 22.59)\n",
      "Epoch: [0][ 7400/10010]\tTime  0.076 ( 0.263)\tData  0.001 ( 0.187)\tLoss 4.0392e+00 (5.1338e+00)\tAcc@1  19.53 (  9.25)\tAcc@5  40.62 ( 22.81)\n",
      "Epoch: [0][ 7500/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.187)\tLoss 4.4991e+00 (5.1205e+00)\tAcc@1  14.06 (  9.38)\tAcc@5  37.50 ( 23.04)\n",
      "Epoch: [0][ 7600/10010]\tTime  0.085 ( 0.264)\tData  0.001 ( 0.187)\tLoss 4.3050e+00 (5.1075e+00)\tAcc@1  16.41 (  9.50)\tAcc@5  35.94 ( 23.27)\n",
      "Epoch: [0][ 7700/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.187)\tLoss 4.2948e+00 (5.0948e+00)\tAcc@1  16.41 (  9.62)\tAcc@5  33.59 ( 23.50)\n",
      "Epoch: [0][ 7800/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.187)\tLoss 3.7432e+00 (5.0822e+00)\tAcc@1  21.09 (  9.74)\tAcc@5  49.22 ( 23.72)\n",
      "Epoch: [0][ 7900/10010]\tTime  0.077 ( 0.264)\tData  0.001 ( 0.188)\tLoss 4.5652e+00 (5.0697e+00)\tAcc@1  10.94 (  9.87)\tAcc@5  31.25 ( 23.93)\n",
      "Epoch: [0][ 8000/10010]\tTime  0.081 ( 0.264)\tData  0.005 ( 0.188)\tLoss 4.2833e+00 (5.0579e+00)\tAcc@1  16.41 (  9.98)\tAcc@5  39.84 ( 24.13)\n",
      "Epoch: [0][ 8100/10010]\tTime  0.074 ( 0.264)\tData  0.001 ( 0.188)\tLoss 3.9850e+00 (5.0458e+00)\tAcc@1  22.66 ( 10.10)\tAcc@5  42.19 ( 24.35)\n",
      "Epoch: [0][ 8200/10010]\tTime  0.075 ( 0.264)\tData  0.001 ( 0.188)\tLoss 4.2649e+00 (5.0333e+00)\tAcc@1  11.72 ( 10.23)\tAcc@5  42.97 ( 24.57)\n",
      "Epoch: [0][ 8300/10010]\tTime  0.074 ( 0.264)\tData  0.001 ( 0.188)\tLoss 4.1644e+00 (5.0217e+00)\tAcc@1  23.44 ( 10.35)\tAcc@5  42.19 ( 24.78)\n",
      "Epoch: [0][ 8400/10010]\tTime  0.074 ( 0.264)\tData  0.001 ( 0.188)\tLoss 4.1447e+00 (5.0106e+00)\tAcc@1  20.31 ( 10.46)\tAcc@5  40.62 ( 24.98)\n",
      "Epoch: [0][ 8500/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.188)\tLoss 3.8318e+00 (4.9997e+00)\tAcc@1  19.53 ( 10.56)\tAcc@5  45.31 ( 25.17)\n",
      "Epoch: [0][ 8600/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.188)\tLoss 4.0737e+00 (4.9890e+00)\tAcc@1  18.75 ( 10.67)\tAcc@5  50.00 ( 25.36)\n",
      "Epoch: [0][ 8700/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.188)\tLoss 3.9657e+00 (4.9786e+00)\tAcc@1  18.75 ( 10.77)\tAcc@5  41.41 ( 25.54)\n",
      "Epoch: [0][ 8800/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 4.2494e+00 (4.9683e+00)\tAcc@1  16.41 ( 10.87)\tAcc@5  37.50 ( 25.73)\n",
      "Epoch: [0][ 8900/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 4.3250e+00 (4.9583e+00)\tAcc@1  20.31 ( 10.97)\tAcc@5  36.72 ( 25.91)\n",
      "Epoch: [0][ 9000/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 4.2762e+00 (4.9485e+00)\tAcc@1  14.84 ( 11.06)\tAcc@5  39.84 ( 26.08)\n",
      "Epoch: [0][ 9100/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 4.0556e+00 (4.9389e+00)\tAcc@1  20.31 ( 11.16)\tAcc@5  39.06 ( 26.25)\n",
      "Epoch: [0][ 9200/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 3.9645e+00 (4.9295e+00)\tAcc@1  22.66 ( 11.26)\tAcc@5  46.09 ( 26.42)\n",
      "Epoch: [0][ 9300/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 3.9954e+00 (4.9204e+00)\tAcc@1  17.19 ( 11.34)\tAcc@5  41.41 ( 26.58)\n",
      "Epoch: [0][ 9400/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 3.9949e+00 (4.9113e+00)\tAcc@1  14.84 ( 11.43)\tAcc@5  41.41 ( 26.74)\n",
      "Epoch: [0][ 9500/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 3.8732e+00 (4.9028e+00)\tAcc@1  23.44 ( 11.51)\tAcc@5  46.09 ( 26.90)\n",
      "Epoch: [0][ 9600/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 4.2825e+00 (4.8946e+00)\tAcc@1  16.41 ( 11.59)\tAcc@5  40.62 ( 27.04)\n",
      "Epoch: [0][ 9700/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 4.1740e+00 (4.8862e+00)\tAcc@1  19.53 ( 11.68)\tAcc@5  35.16 ( 27.19)\n",
      "Epoch: [0][ 9800/10010]\tTime  0.074 ( 0.265)\tData  0.001 ( 0.189)\tLoss 4.2832e+00 (4.8781e+00)\tAcc@1  21.88 ( 11.76)\tAcc@5  39.84 ( 27.34)\n",
      "Epoch: [0][ 9900/10010]\tTime  0.074 ( 0.266)\tData  0.001 ( 0.190)\tLoss 3.9355e+00 (4.8700e+00)\tAcc@1  22.66 ( 11.85)\tAcc@5  42.19 ( 27.48)\n",
      "Epoch: [0][10000/10010]\tTime  0.074 ( 0.266)\tData  0.001 ( 0.190)\tLoss 4.2055e+00 (4.8622e+00)\tAcc@1  17.97 ( 11.93)\tAcc@5  39.84 ( 27.62)\n",
      "Test: [  0/391]\tTime  1.527 ( 1.527)\tLoss 2.9605e+00 (2.9605e+00)\tAcc@1  33.59 ( 33.59)\tAcc@5  67.97 ( 67.97)\n",
      "Test: [100/391]\tTime  0.892 ( 0.318)\tLoss 3.6277e+00 (3.3387e+00)\tAcc@1  15.62 ( 26.41)\tAcc@5  47.66 ( 54.00)\n",
      "Test: [200/391]\tTime  0.628 ( 0.316)\tLoss 4.4226e+00 (3.5169e+00)\tAcc@1  10.94 ( 25.10)\tAcc@5  36.72 ( 51.05)\n",
      "Test: [300/391]\tTime  0.942 ( 0.314)\tLoss 4.2628e+00 (3.6886e+00)\tAcc@1  29.69 ( 23.88)\tAcc@5  42.97 ( 48.37)\n",
      " * Acc@1 23.484 Acc@5 47.740\n",
      "lr: [0.05]\n",
      "Epoch: [1][    0/10010]\tTime  1.557 ( 1.557)\tData  1.483 ( 1.483)\tLoss 3.9850e+00 (3.9850e+00)\tAcc@1  24.22 ( 24.22)\tAcc@5  42.97 ( 42.97)\n",
      "Epoch: [1][  100/10010]\tTime  0.289 ( 0.272)\tData  0.216 ( 0.199)\tLoss 3.9486e+00 (4.0266e+00)\tAcc@1  17.97 ( 20.40)\tAcc@5  35.94 ( 41.96)\n",
      "Epoch: [1][  200/10010]\tTime  0.268 ( 0.264)\tData  0.195 ( 0.190)\tLoss 3.8542e+00 (4.0533e+00)\tAcc@1  24.22 ( 19.94)\tAcc@5  45.31 ( 41.49)\n",
      "Epoch: [1][  300/10010]\tTime  0.074 ( 0.262)\tData  0.001 ( 0.189)\tLoss 4.4587e+00 (4.0492e+00)\tAcc@1  15.62 ( 19.93)\tAcc@5  35.94 ( 41.89)\n",
      "Epoch: [1][  400/10010]\tTime  0.276 ( 0.260)\tData  0.203 ( 0.187)\tLoss 3.8281e+00 (4.0480e+00)\tAcc@1  16.41 ( 19.86)\tAcc@5  46.09 ( 41.87)\n",
      "Epoch: [1][  500/10010]\tTime  0.250 ( 0.259)\tData  0.177 ( 0.186)\tLoss 4.1494e+00 (4.0561e+00)\tAcc@1  21.09 ( 19.79)\tAcc@5  42.19 ( 41.81)\n",
      "Epoch: [1][  600/10010]\tTime  0.074 ( 0.258)\tData  0.001 ( 0.185)\tLoss 4.1418e+00 (4.0523e+00)\tAcc@1  16.41 ( 19.83)\tAcc@5  36.72 ( 41.87)\n",
      "Epoch: [1][  700/10010]\tTime  0.076 ( 0.258)\tData  0.004 ( 0.185)\tLoss 4.1975e+00 (4.0511e+00)\tAcc@1  19.53 ( 19.86)\tAcc@5  38.28 ( 41.89)\n",
      "Epoch: [1][  800/10010]\tTime  0.074 ( 0.259)\tData  0.001 ( 0.186)\tLoss 3.6717e+00 (4.0532e+00)\tAcc@1  21.88 ( 19.89)\tAcc@5  46.88 ( 41.87)\n",
      "Epoch: [1][  900/10010]\tTime  0.080 ( 0.259)\tData  0.007 ( 0.186)\tLoss 3.8416e+00 (4.0480e+00)\tAcc@1  21.09 ( 19.95)\tAcc@5  44.53 ( 42.02)\n",
      "Epoch: [1][ 1000/10010]\tTime  0.081 ( 0.259)\tData  0.001 ( 0.186)\tLoss 3.9862e+00 (4.0473e+00)\tAcc@1  17.97 ( 19.99)\tAcc@5  45.31 ( 42.05)\n",
      "Epoch: [1][ 1100/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.3378e+00 (4.0499e+00)\tAcc@1  21.09 ( 19.99)\tAcc@5  40.62 ( 42.02)\n",
      "Epoch: [1][ 1200/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.3667e+00 (4.0533e+00)\tAcc@1  13.28 ( 19.94)\tAcc@5  34.38 ( 42.01)\n",
      "Epoch: [1][ 1300/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.3713e+00 (4.0539e+00)\tAcc@1  20.31 ( 19.93)\tAcc@5  38.28 ( 42.02)\n",
      "Epoch: [1][ 1400/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.1087e+00 (4.0540e+00)\tAcc@1  18.75 ( 19.90)\tAcc@5  38.28 ( 42.04)\n",
      "Epoch: [1][ 1500/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.9519e+00 (4.0529e+00)\tAcc@1  17.19 ( 19.87)\tAcc@5  43.75 ( 42.05)\n",
      "Epoch: [1][ 1600/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.9379e+00 (4.0526e+00)\tAcc@1  19.53 ( 19.91)\tAcc@5  41.41 ( 42.05)\n",
      "Epoch: [1][ 1700/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.7074e+00 (4.0522e+00)\tAcc@1  25.00 ( 19.89)\tAcc@5  46.09 ( 42.04)\n",
      "Epoch: [1][ 1800/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.2681e+00 (4.0527e+00)\tAcc@1  12.50 ( 19.89)\tAcc@5  32.03 ( 42.02)\n",
      "Epoch: [1][ 1900/10010]\tTime  0.084 ( 0.260)\tData  0.012 ( 0.187)\tLoss 3.8644e+00 (4.0522e+00)\tAcc@1  21.88 ( 19.87)\tAcc@5  46.09 ( 42.05)\n",
      "Epoch: [1][ 2000/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.187)\tLoss 3.6982e+00 (4.0513e+00)\tAcc@1  27.34 ( 19.88)\tAcc@5  50.00 ( 42.06)\n",
      "Epoch: [1][ 2100/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.187)\tLoss 4.2800e+00 (4.0520e+00)\tAcc@1  15.62 ( 19.85)\tAcc@5  34.38 ( 42.04)\n",
      "Epoch: [1][ 2200/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.187)\tLoss 3.8802e+00 (4.0518e+00)\tAcc@1  24.22 ( 19.85)\tAcc@5  43.75 ( 42.05)\n",
      "Epoch: [1][ 2300/10010]\tTime  0.075 ( 0.260)\tData  0.002 ( 0.187)\tLoss 4.3242e+00 (4.0521e+00)\tAcc@1  17.97 ( 19.84)\tAcc@5  39.06 ( 42.04)\n",
      "Epoch: [1][ 2400/10010]\tTime  0.444 ( 0.261)\tData  0.371 ( 0.188)\tLoss 3.8567e+00 (4.0504e+00)\tAcc@1  19.53 ( 19.87)\tAcc@5  45.31 ( 42.06)\n",
      "Epoch: [1][ 2500/10010]\tTime  0.076 ( 0.261)\tData  0.003 ( 0.188)\tLoss 4.1852e+00 (4.0503e+00)\tAcc@1  16.41 ( 19.88)\tAcc@5  36.72 ( 42.04)\n",
      "Epoch: [1][ 2600/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.2287e+00 (4.0495e+00)\tAcc@1  16.41 ( 19.88)\tAcc@5  38.28 ( 42.05)\n",
      "Epoch: [1][ 2700/10010]\tTime  0.084 ( 0.261)\tData  0.005 ( 0.188)\tLoss 4.0467e+00 (4.0479e+00)\tAcc@1  17.19 ( 19.87)\tAcc@5  42.97 ( 42.07)\n",
      "Epoch: [1][ 2800/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1514e+00 (4.0486e+00)\tAcc@1  17.19 ( 19.86)\tAcc@5  42.97 ( 42.06)\n",
      "Epoch: [1][ 2900/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.2815e+00 (4.0486e+00)\tAcc@1  13.28 ( 19.86)\tAcc@5  39.84 ( 42.05)\n",
      "Epoch: [1][ 3000/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.9987e+00 (4.0486e+00)\tAcc@1  16.41 ( 19.86)\tAcc@5  46.88 ( 42.04)\n",
      "Epoch: [1][ 3100/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0304e+00 (4.0486e+00)\tAcc@1  20.31 ( 19.86)\tAcc@5  37.50 ( 42.05)\n",
      "Epoch: [1][ 3200/10010]\tTime  0.075 ( 0.261)\tData  0.002 ( 0.188)\tLoss 4.1768e+00 (4.0484e+00)\tAcc@1  20.31 ( 19.87)\tAcc@5  42.97 ( 42.04)\n",
      "Epoch: [1][ 3300/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.8619e+00 (4.0494e+00)\tAcc@1  21.88 ( 19.87)\tAcc@5  42.97 ( 42.03)\n",
      "Epoch: [1][ 3400/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.3129e+00 (4.0503e+00)\tAcc@1  17.97 ( 19.86)\tAcc@5  38.28 ( 42.02)\n",
      "Epoch: [1][ 3500/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1483e+00 (4.0499e+00)\tAcc@1  19.53 ( 19.88)\tAcc@5  41.41 ( 42.03)\n",
      "Epoch: [1][ 3600/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1261e+00 (4.0498e+00)\tAcc@1  18.75 ( 19.87)\tAcc@5  39.84 ( 42.03)\n",
      "Epoch: [1][ 3700/10010]\tTime  0.075 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.6014e+00 (4.0497e+00)\tAcc@1  25.00 ( 19.88)\tAcc@5  46.88 ( 42.05)\n",
      "Epoch: [1][ 3800/10010]\tTime  0.076 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0966e+00 (4.0491e+00)\tAcc@1  20.31 ( 19.89)\tAcc@5  43.75 ( 42.07)\n",
      "Epoch: [1][ 3900/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.8530e+00 (4.0498e+00)\tAcc@1  23.44 ( 19.89)\tAcc@5  46.88 ( 42.05)\n",
      "Epoch: [1][ 4000/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0264e+00 (4.0498e+00)\tAcc@1  19.53 ( 19.89)\tAcc@5  42.19 ( 42.05)\n",
      "Epoch: [1][ 4100/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1856e+00 (4.0497e+00)\tAcc@1  23.44 ( 19.90)\tAcc@5  39.06 ( 42.05)\n",
      "Epoch: [1][ 4200/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.8627e+00 (4.0493e+00)\tAcc@1  19.53 ( 19.90)\tAcc@5  38.28 ( 42.05)\n",
      "Epoch: [1][ 4300/10010]\tTime  0.075 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.2409e+00 (4.0488e+00)\tAcc@1  17.19 ( 19.91)\tAcc@5  37.50 ( 42.07)\n",
      "Epoch: [1][ 4400/10010]\tTime  0.179 ( 0.261)\tData  0.106 ( 0.188)\tLoss 3.9129e+00 (4.0487e+00)\tAcc@1  21.09 ( 19.92)\tAcc@5  43.75 ( 42.06)\n",
      "Epoch: [1][ 4500/10010]\tTime  0.326 ( 0.261)\tData  0.253 ( 0.188)\tLoss 4.0899e+00 (4.0494e+00)\tAcc@1  20.31 ( 19.91)\tAcc@5  41.41 ( 42.04)\n",
      "Epoch: [1][ 4600/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.9978e+00 (4.0497e+00)\tAcc@1  21.09 ( 19.91)\tAcc@5  47.66 ( 42.05)\n",
      "Epoch: [1][ 4700/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.9547e+00 (4.0502e+00)\tAcc@1  14.84 ( 19.91)\tAcc@5  43.75 ( 42.05)\n",
      "Epoch: [1][ 4800/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0997e+00 (4.0507e+00)\tAcc@1  19.53 ( 19.90)\tAcc@5  42.19 ( 42.03)\n",
      "Epoch: [1][ 4900/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0373e+00 (4.0514e+00)\tAcc@1  23.44 ( 19.89)\tAcc@5  42.19 ( 42.01)\n",
      "Epoch: [1][ 5000/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.9885e+00 (4.0522e+00)\tAcc@1  19.53 ( 19.89)\tAcc@5  42.97 ( 41.99)\n",
      "Epoch: [1][ 5100/10010]\tTime  0.077 ( 0.261)\tData  0.004 ( 0.188)\tLoss 4.1722e+00 (4.0521e+00)\tAcc@1  21.09 ( 19.88)\tAcc@5  36.72 ( 41.99)\n",
      "Epoch: [1][ 5200/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.9994e+00 (4.0522e+00)\tAcc@1  15.62 ( 19.88)\tAcc@5  39.84 ( 42.00)\n",
      "Epoch: [1][ 5300/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.2459e+00 (4.0525e+00)\tAcc@1  16.41 ( 19.87)\tAcc@5  37.50 ( 41.99)\n",
      "Epoch: [1][ 5400/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.2694e+00 (4.0520e+00)\tAcc@1  15.62 ( 19.88)\tAcc@5  37.50 ( 41.99)\n",
      "Epoch: [1][ 5500/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1420e+00 (4.0519e+00)\tAcc@1  20.31 ( 19.88)\tAcc@5  47.66 ( 41.99)\n",
      "Epoch: [1][ 5600/10010]\tTime  0.082 ( 0.261)\tData  0.009 ( 0.188)\tLoss 3.9716e+00 (4.0521e+00)\tAcc@1  16.41 ( 19.88)\tAcc@5  40.62 ( 41.98)\n",
      "Epoch: [1][ 5700/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.5790e+00 (4.0518e+00)\tAcc@1  25.00 ( 19.88)\tAcc@5  45.31 ( 41.98)\n",
      "Epoch: [1][ 5800/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1747e+00 (4.0521e+00)\tAcc@1  21.88 ( 19.89)\tAcc@5  39.06 ( 41.98)\n",
      "Epoch: [1][ 5900/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1717e+00 (4.0522e+00)\tAcc@1  21.09 ( 19.88)\tAcc@5  46.09 ( 41.99)\n",
      "Epoch: [1][ 6000/10010]\tTime  0.073 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0233e+00 (4.0522e+00)\tAcc@1  19.53 ( 19.89)\tAcc@5  40.62 ( 41.99)\n",
      "Epoch: [1][ 6100/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1835e+00 (4.0521e+00)\tAcc@1  16.41 ( 19.89)\tAcc@5  40.62 ( 41.99)\n",
      "Epoch: [1][ 6200/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.8967e+00 (4.0524e+00)\tAcc@1  25.78 ( 19.89)\tAcc@5  46.09 ( 41.98)\n",
      "Epoch: [1][ 6300/10010]\tTime  0.086 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1311e+00 (4.0523e+00)\tAcc@1  17.19 ( 19.89)\tAcc@5  43.75 ( 41.99)\n",
      "Epoch: [1][ 6400/10010]\tTime  0.611 ( 0.261)\tData  0.538 ( 0.188)\tLoss 4.2946e+00 (4.0520e+00)\tAcc@1  14.06 ( 19.90)\tAcc@5  37.50 ( 42.00)\n",
      "Epoch: [1][ 6500/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1339e+00 (4.0515e+00)\tAcc@1  17.19 ( 19.90)\tAcc@5  39.84 ( 42.01)\n",
      "Epoch: [1][ 6600/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0940e+00 (4.0514e+00)\tAcc@1  21.88 ( 19.91)\tAcc@5  39.84 ( 42.01)\n",
      "Epoch: [1][ 6700/10010]\tTime  0.208 ( 0.261)\tData  0.135 ( 0.188)\tLoss 4.2456e+00 (4.0519e+00)\tAcc@1  18.75 ( 19.91)\tAcc@5  35.16 ( 42.00)\n",
      "Epoch: [1][ 6800/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0572e+00 (4.0517e+00)\tAcc@1  23.44 ( 19.91)\tAcc@5  42.97 ( 42.00)\n",
      "Epoch: [1][ 6900/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0738e+00 (4.0520e+00)\tAcc@1  23.44 ( 19.91)\tAcc@5  46.88 ( 42.00)\n",
      "Epoch: [1][ 7000/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0808e+00 (4.0521e+00)\tAcc@1  14.84 ( 19.91)\tAcc@5  44.53 ( 42.00)\n",
      "Epoch: [1][ 7100/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.0515e+00 (4.0521e+00)\tAcc@1  16.41 ( 19.91)\tAcc@5  42.97 ( 41.99)\n",
      "Epoch: [1][ 7200/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.188)\tLoss 3.9611e+00 (4.0519e+00)\tAcc@1  22.66 ( 19.91)\tAcc@5  47.66 ( 42.00)\n",
      "Epoch: [1][ 7300/10010]\tTime  0.079 ( 0.261)\tData  0.001 ( 0.188)\tLoss 4.1737e+00 (4.0521e+00)\tAcc@1  19.53 ( 19.91)\tAcc@5  39.06 ( 42.00)\n",
      "Epoch: [1][ 7400/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.187)\tLoss 3.9652e+00 (4.0514e+00)\tAcc@1  22.66 ( 19.92)\tAcc@5  47.66 ( 42.01)\n",
      "Epoch: [1][ 7500/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.187)\tLoss 4.0336e+00 (4.0513e+00)\tAcc@1  19.53 ( 19.92)\tAcc@5  41.41 ( 42.00)\n",
      "Epoch: [1][ 7600/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.187)\tLoss 4.4795e+00 (4.0507e+00)\tAcc@1  14.84 ( 19.92)\tAcc@5  36.72 ( 42.01)\n",
      "Epoch: [1][ 7700/10010]\tTime  0.074 ( 0.261)\tData  0.001 ( 0.187)\tLoss 4.0994e+00 (4.0504e+00)\tAcc@1  21.88 ( 19.93)\tAcc@5  40.62 ( 42.03)\n",
      "Epoch: [1][ 7800/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.0247e+00 (4.0505e+00)\tAcc@1  15.62 ( 19.93)\tAcc@5  42.19 ( 42.03)\n",
      "Epoch: [1][ 7900/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.0948e+00 (4.0505e+00)\tAcc@1  15.62 ( 19.93)\tAcc@5  42.19 ( 42.03)\n",
      "Epoch: [1][ 8000/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.1024e+00 (4.0505e+00)\tAcc@1  24.22 ( 19.93)\tAcc@5  35.94 ( 42.02)\n",
      "Epoch: [1][ 8100/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.8562e+00 (4.0507e+00)\tAcc@1  20.31 ( 19.93)\tAcc@5  46.09 ( 42.02)\n",
      "Epoch: [1][ 8200/10010]\tTime  0.158 ( 0.260)\tData  0.085 ( 0.187)\tLoss 3.9961e+00 (4.0506e+00)\tAcc@1  25.00 ( 19.92)\tAcc@5  40.62 ( 42.02)\n",
      "Epoch: [1][ 8300/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.0992e+00 (4.0507e+00)\tAcc@1  24.22 ( 19.93)\tAcc@5  42.19 ( 42.02)\n",
      "Epoch: [1][ 8400/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.0669e+00 (4.0510e+00)\tAcc@1  17.97 ( 19.92)\tAcc@5  40.62 ( 42.02)\n",
      "Epoch: [1][ 8500/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.8745e+00 (4.0508e+00)\tAcc@1  24.22 ( 19.93)\tAcc@5  46.09 ( 42.02)\n",
      "Epoch: [1][ 8600/10010]\tTime  0.078 ( 0.260)\tData  0.005 ( 0.187)\tLoss 4.0192e+00 (4.0509e+00)\tAcc@1  21.88 ( 19.93)\tAcc@5  41.41 ( 42.02)\n",
      "Epoch: [1][ 8700/10010]\tTime  0.344 ( 0.260)\tData  0.272 ( 0.187)\tLoss 3.9133e+00 (4.0511e+00)\tAcc@1  23.44 ( 19.93)\tAcc@5  41.41 ( 42.02)\n",
      "Epoch: [1][ 8800/10010]\tTime  0.211 ( 0.260)\tData  0.138 ( 0.187)\tLoss 4.2725e+00 (4.0509e+00)\tAcc@1  17.97 ( 19.93)\tAcc@5  39.84 ( 42.02)\n",
      "Epoch: [1][ 8900/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.9637e+00 (4.0510e+00)\tAcc@1  22.66 ( 19.93)\tAcc@5  48.44 ( 42.02)\n",
      "Epoch: [1][ 9000/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.8074e+00 (4.0506e+00)\tAcc@1  17.97 ( 19.94)\tAcc@5  49.22 ( 42.03)\n",
      "Epoch: [1][ 9100/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.0593e+00 (4.0509e+00)\tAcc@1  13.28 ( 19.93)\tAcc@5  39.84 ( 42.03)\n",
      "Epoch: [1][ 9200/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.1257e+00 (4.0506e+00)\tAcc@1  17.97 ( 19.94)\tAcc@5  42.19 ( 42.03)\n",
      "Epoch: [1][ 9300/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.1312e+00 (4.0508e+00)\tAcc@1  21.88 ( 19.94)\tAcc@5  32.81 ( 42.03)\n",
      "Epoch: [1][ 9400/10010]\tTime  0.078 ( 0.260)\tData  0.005 ( 0.187)\tLoss 4.0094e+00 (4.0506e+00)\tAcc@1  17.19 ( 19.95)\tAcc@5  40.62 ( 42.03)\n",
      "Epoch: [1][ 9500/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.7061e+00 (4.0504e+00)\tAcc@1  23.44 ( 19.95)\tAcc@5  50.78 ( 42.03)\n",
      "Epoch: [1][ 9600/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.7397e+00 (4.0505e+00)\tAcc@1  24.22 ( 19.96)\tAcc@5  48.44 ( 42.04)\n",
      "Epoch: [1][ 9700/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.8353e+00 (4.0507e+00)\tAcc@1  22.66 ( 19.95)\tAcc@5  45.31 ( 42.03)\n",
      "Epoch: [1][ 9800/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 4.1346e+00 (4.0509e+00)\tAcc@1  14.06 ( 19.95)\tAcc@5  38.28 ( 42.03)\n",
      "Epoch: [1][ 9900/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.7846e+00 (4.0510e+00)\tAcc@1  21.09 ( 19.95)\tAcc@5  48.44 ( 42.03)\n",
      "Epoch: [1][10000/10010]\tTime  0.074 ( 0.260)\tData  0.001 ( 0.187)\tLoss 3.9979e+00 (4.0511e+00)\tAcc@1  17.97 ( 19.95)\tAcc@5  42.19 ( 42.02)\n",
      "Test: [  0/391]\tTime  1.390 ( 1.390)\tLoss 2.9292e+00 (2.9292e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  67.97 ( 67.97)\n",
      "Test: [100/391]\tTime  0.389 ( 0.318)\tLoss 3.6405e+00 (3.3014e+00)\tAcc@1  12.50 ( 26.65)\tAcc@5  44.53 ( 54.62)\n",
      "Test: [200/391]\tTime  0.346 ( 0.317)\tLoss 4.4505e+00 (3.4906e+00)\tAcc@1  11.72 ( 25.26)\tAcc@5  35.94 ( 51.45)\n",
      "Test: [300/391]\tTime  0.509 ( 0.314)\tLoss 4.3454e+00 (3.6784e+00)\tAcc@1  28.91 ( 23.88)\tAcc@5  40.62 ( 48.65)\n",
      " * Acc@1 23.504 Acc@5 47.892\n",
      "lr: [0.0]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044f5f5",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ded169",
   "metadata": {
    "id": "d3faf0cd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
